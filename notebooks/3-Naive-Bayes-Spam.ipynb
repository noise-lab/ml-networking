{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes Spam Classifier\n",
    "\n",
    "Probability is a powerful tool that lets us answer interesting questions about data, and it serves as the foundation of a commonly used machine learning technique for classification We'll also be building a Naïve Bayes classifier from scratch, so you'll get hands-on experience coding a machine learning classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building a Naïve Bayes Classifier from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Data\n",
    "\n",
    "The data was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more details [here](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/csv/sms.csv.gz', compression='gzip', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Statistics\n",
    "\n",
    "Let us see what fraction of the dataset is ham, and what fraction of the dataset is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 86.6% of messages are ham, and 13.4% of messages are labeled spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training and Testing Data\n",
    "\n",
    "Now, let's split our data into training and testing tests. A common split of training and testing data is 80% in the training set, 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(data['SMS'], data['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "training_data = pd.DataFrame()\n",
    "training_data['SMS'] = X_train\n",
    "training_data['Label'] = y_train\n",
    "\n",
    "testing_data = pd.DataFrame()\n",
    "testing_data['SMS'] = X_test\n",
    "testing_data['Label'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a little sanity check, let's verify that the percentages of spam and non-spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865829\n",
       "spam    0.134171\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.866368\n",
       "spam    0.133632\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Let's do some data cleaning: \n",
    "1. remove all punctuation\n",
    "2. make all words lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data['SMS'] = training_data['SMS'].str.replace('\\W',' ').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now collect the unique set of words that occur in the training data, otherwise known as the **vocabulary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "\n",
    "# make a word list from each SMS\n",
    "training_data['SMS'] = training_data['SMS'].str.split()\n",
    "\n",
    "# aggregate all word lists into one\n",
    "for sms in training_data['SMS']:\n",
    "    vocabulary += sms\n",
    "    \n",
    "# remove duplicates from the list\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute how many times each word occurs in each SMS message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_data['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_data['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "word_counts_df = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>callers</th>\n",
       "      <th>reception</th>\n",
       "      <th>neither</th>\n",
       "      <th>painting</th>\n",
       "      <th>mobstorequiz10ppm</th>\n",
       "      <th>gamb</th>\n",
       "      <th>nice</th>\n",
       "      <th>dict</th>\n",
       "      <th>...</th>\n",
       "      <th>wrkin</th>\n",
       "      <th>gmw</th>\n",
       "      <th>08709222922</th>\n",
       "      <th>drinks</th>\n",
       "      <th>wen</th>\n",
       "      <th>kicks</th>\n",
       "      <th>asda</th>\n",
       "      <th>frnds</th>\n",
       "      <th>dobby</th>\n",
       "      <th>cusoon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[reply, to, win, 100, weekly, where, will, the...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hello, sort, of, out, in, town, already, that...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[how, come, guoyang, go, n, tell, her, then, u...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hey, sathya, till, now, we, dint, meet, not, ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[orange, brings, you, ringtones, from, all, ti...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>[hi, wlcome, back, did, wonder, if, you, got, ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>[sorry, i, ll, call, later]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>[prabha, i, m, soryda, realy, frm, heart, i, m...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>[nt, joking, seriously, i, told]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>[did, he, just, say, somebody, is, named, tampa]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 7743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label  callers  \\\n",
       "0     [reply, to, win, 100, weekly, where, will, the...  spam        0   \n",
       "1     [hello, sort, of, out, in, town, already, that...   ham        0   \n",
       "2     [how, come, guoyang, go, n, tell, her, then, u...   ham        0   \n",
       "3     [hey, sathya, till, now, we, dint, meet, not, ...   ham        0   \n",
       "4     [orange, brings, you, ringtones, from, all, ti...  spam        0   \n",
       "...                                                 ...   ...      ...   \n",
       "4452  [hi, wlcome, back, did, wonder, if, you, got, ...   ham        0   \n",
       "4453                        [sorry, i, ll, call, later]   ham        0   \n",
       "4454  [prabha, i, m, soryda, realy, frm, heart, i, m...   ham        0   \n",
       "4455                   [nt, joking, seriously, i, told]   ham        0   \n",
       "4456   [did, he, just, say, somebody, is, named, tampa]   ham        0   \n",
       "\n",
       "      reception  neither  painting  mobstorequiz10ppm  gamb  nice  dict  ...  \\\n",
       "0             0        0         0                  0     0     0     0  ...   \n",
       "1             0        0         0                  0     0     0     0  ...   \n",
       "2             0        0         0                  0     0     0     0  ...   \n",
       "3             0        0         0                  0     0     0     0  ...   \n",
       "4             0        0         0                  0     0     0     0  ...   \n",
       "...         ...      ...       ...                ...   ...   ...   ...  ...   \n",
       "4452          0        0         0                  0     0     0     0  ...   \n",
       "4453          0        0         0                  0     0     0     0  ...   \n",
       "4454          0        0         0                  0     0     0     0  ...   \n",
       "4455          0        0         0                  0     0     0     0  ...   \n",
       "4456          0        0         0                  0     0     0     0  ...   \n",
       "\n",
       "      wrkin  gmw  08709222922  drinks  wen  kicks  asda  frnds  dobby  cusoon  \n",
       "0         0    0            0       0    0      0     0      0      0       0  \n",
       "1         0    0            0       0    0      0     0      0      0       0  \n",
       "2         0    0            0       0    0      0     0      0      0       0  \n",
       "3         0    0            0       0    0      0     0      0      0       0  \n",
       "4         0    0            0       0    0      0     0      0      0       0  \n",
       "...     ...  ...          ...     ...  ...    ...   ...    ...    ...     ...  \n",
       "4452      0    0            0       0    0      0     0      0      0       0  \n",
       "4453      0    0            0       0    0      0     0      0      0       0  \n",
       "4454      0    0            0       0    0      0     0      0      0       0  \n",
       "4455      0    0            0       0    0      0     0      0      0       0  \n",
       "4456      0    0            0       0    0      0     0      0      0       0  \n",
       "\n",
       "[4457 rows x 7743 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.concat([training_data, word_counts_df], axis=1)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataframe into spam and ham\n",
    "spam = training_data[training_data['Label'] == 'spam']\n",
    "ham = training_data[training_data['Label'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13417096701817366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the probability of spam or ham (our prior probabilities for Bayes' Rule)\n",
    "p_spam = len(spam) / len(training_data)\n",
    "p_ham = len(ham) / len(training_data)\n",
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total number of words in spam messages\n",
    "n_spam = 0\n",
    "\n",
    "for sms in spam['SMS']:\n",
    "    len_sms = len(sms)\n",
    "    n_spam += len_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total number of words in ham messages\n",
    "n_ham = 0\n",
    "\n",
    "for sms in ham['SMS']:\n",
    "    len_sms = len(sms)\n",
    "    n_ham += len_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating number of unique words in training data\n",
    "n_vocabulary = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization parameter for non-occurrences of words\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize two dictionaries to store probabilities\n",
    "spam_dict = {word : 0 for word in vocabulary}\n",
    "ham_dict = {word : 0 for word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all words in spam and ham messages\n",
    "\n",
    "spam_words = []\n",
    "for sms in spam['SMS']:\n",
    "    spam_words += sms\n",
    "    \n",
    "ham_words = []\n",
    "for sms in ham['SMS']:\n",
    "    ham_words += sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to calculate $P(x_i\\ |\\ y = Spam)$ and $P(x_i\\ |\\ y = Ham)$ for all words $x_i$ in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique_word in vocabulary:\n",
    "    # calculating how many times each word in vocabulary occurs in spam and ham messages\n",
    "    spam_count = 0\n",
    "    ham_count = 0\n",
    "    for word in spam_words:\n",
    "        if word == unique_word:\n",
    "            spam_count += 1\n",
    "    \n",
    "    for word in ham_words:\n",
    "        if word == unique_word:\n",
    "            ham_count += 1\n",
    "            \n",
    "    # calculate probability that the word appears given that it is spam or ham\n",
    "    p_word_spam = (spam_count + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    p_word_ham = (ham_count + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    \n",
    "    # finally update dictionaries with their respective probabilities\n",
    "    spam_dict[unique_word] = p_word_spam\n",
    "    ham_dict[unique_word] = p_word_ham\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define our spam filter function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # calculate the probability that the message is SPAM given set of words\n",
    "    p_spam_given_message = p_spam\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            prob = spam_dict[word]\n",
    "        else:\n",
    "            prob = alpha / (n_spam + alpha * n_vocabulary)\n",
    "            \n",
    "        p_spam_given_message *= prob\n",
    "\n",
    "    # calculate the probability that the message is HAM given set of words\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            prob = ham_dict[word]\n",
    "        else:\n",
    "            prob = alpha / (n_ham + alpha * n_vocabulary)\n",
    "            \n",
    "        p_ham_given_message *= prob\n",
    "    \n",
    "    # these are not technically conditional probabilities.\n",
    "    # these are the two quantities that Naive Bayes compares: prior times likelihood.\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "### Example Messages\n",
    "Let's test the spam classifier on a few messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.7102832995008655e-25\n",
      "P(Ham|message): 8.156894573341021e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Alex, then see u there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.090971907616407e-24\n",
      "P(Ham|message): 2.7511284153561355e-28\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('YOU WIN THE PRIZE MONEY JACKPOT! CALL 14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on Test Set\n",
    "\n",
    "With obvious spam and non-spam, the classifier seems to be working in the way we would expect. Let's properly evaluate model performance using test data now. We just need to update our function to actual return something first, rather than print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    # we need to calculate the probabilities that the message is spam given message\n",
    "    p_spam_given_message = p_spam\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            prob = spam_dict[word]\n",
    "        else:\n",
    "            prob = alpha / (n_spam + alpha * n_vocabulary)\n",
    "            \n",
    "        p_spam_given_message *= prob\n",
    "     \n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            prob = ham_dict[word]\n",
    "        else:\n",
    "            prob = alpha / (n_ham + alpha * n_vocabulary)\n",
    "            \n",
    "        p_ham_given_message *= prob\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>Label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>Squeeeeeze!! This is christmas hug.. If u lik ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>And also I've sorta blown him off a couple tim...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Mmm thats better now i got a roast down me! i...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>Mm have some kanji dont eat anything heavy ok</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>So there's a ring that comes with the guys cos...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>Den only weekdays got special price... Haiz......</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>I not busy juz dun wan 2 go so early.. Hee..</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>How are you enjoying this semester? Take care ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>G.W.R</td>\n",
       "      <td>ham</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    SMS Label predicted\n",
       "3245  Squeeeeeze!! This is christmas hug.. If u lik ...   ham       ham\n",
       "944   And also I've sorta blown him off a couple tim...   ham       ham\n",
       "1044  Mmm thats better now i got a roast down me! i...   ham       ham\n",
       "2484      Mm have some kanji dont eat anything heavy ok   ham       ham\n",
       "812   So there's a ring that comes with the guys cos...   ham       ham\n",
       "...                                                 ...   ...       ...\n",
       "4264  Den only weekdays got special price... Haiz......   ham       ham\n",
       "2439      I not busy juz dun wan 2 go so early.. Hee..    ham       ham\n",
       "5556  Yes i have. So that's why u texted. Pshew...mi...   ham       ham\n",
       "4205  How are you enjoying this semester? Take care ...   ham       ham\n",
       "4293                                              G.W.R   ham       ham\n",
       "\n",
       "[1115 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data['predicted'] = testing_data['SMS'].apply(classify_test_set)\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(testing_data)\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in testing_data.iterrows():\n",
    "    actual_classifcation = row[1]['Label']\n",
    "    predicted_classifcation = row[1]['predicted']\n",
    "    if actual_classifcation == predicted_classifcation:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829596412556054\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
